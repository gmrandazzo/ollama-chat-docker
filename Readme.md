# Lightweight Web UI for Ollama and AI Models

## Overview
This project provides a lightweight web user interface (UI) that enables seamless pulling, management, and execution of Ollama models as well as support for running any compatible AI model you prefer. It is designed to be simple and intuitive, making it easy to experiment with and deploy AI models locally or remotely.

## Features
- Pull Ollama AI models effortlessly from available repositories
- Manage multiple AI models through a clean web interface
- Run Ollama models and any other compatible AI models with ease
- Lightweight, fast, and easy to set up

## Getting Started

### Prerequisites
- Node.js (or your chosen platform runtime)
- Access to Ollama model repositories or other compatible AI model sources
- Web browser for UI access

### Installation
1. Clone this repository:
2. Install docker
3. Start tthe docker compose with
```
docker compose up -d --build
```

### Usage
Connect to the webui http://localhost:8085 and interact with ollama webui


## Contributing
Contributions and feedback are welcome! Please open issues or submit pull requests for bug fixes, features, or improvements.

## License
This project is licensed under the GNU Affero General Public License (AGPL) version 3 or later. See the LICENSE file for details.


## Contact
For questions or support, please contact Giuseppe Marco Randazzo <gmrandazzo@gmail.com>.

